{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Katha Patel\n",
    "# Roll No : 41\n",
    "# GR No : 11810454\n",
    "# Assignment 7 - Sentiment Analysis of twitter data using Python\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trailer…</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>or i just worry too much?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>missin' someone badly. ha ha 'someone'. that's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>Missing @kieronhughes and looking forward to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Missing @smartbrain from BKK na.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Missing @twisteddspirit, why did you have to m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Missing Amarillo and the lake, but loving Temp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentiment_text  sentiment\n",
       "0              is so sad for my APL friend.............          0\n",
       "1                        I missed the New Moon trailer…          0\n",
       "2     .. Omgaga. Im sooo  im gunna CRy. I've been at...          0\n",
       "3              i think mi bf is cheating on me!!!   ...          0\n",
       "4                     or i just worry too much?                  0\n",
       "...                                                 ...        ...\n",
       "1128  missin' someone badly. ha ha 'someone'. that's...          1\n",
       "1129  Missing @kieronhughes and looking forward to s...          1\n",
       "1130                  Missing @smartbrain from BKK na.           1\n",
       "1131  Missing @twisteddspirit, why did you have to m...          1\n",
       "1132  Missing Amarillo and the lake, but loving Temp...          1\n",
       "\n",
       "[1133 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/tweets1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1133, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment_text\n",
       "sentiment                \n",
       "0                     700\n",
       "1                     433"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words form the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                is so sad for my APL friend.............\n",
       "1                          I missed the New Moon trailer…\n",
       "2       .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
       "3                i think mi bf is cheating on me!!!   ...\n",
       "4                       or i just worry too much?        \n",
       "                              ...                        \n",
       "1128    missin' someone badly. ha ha 'someone'. that's...\n",
       "1129    Missing @kieronhughes and looking forward to s...\n",
       "1130                    Missing @smartbrain from BKK na. \n",
       "1131    Missing @twisteddspirit, why did you have to m...\n",
       "1132    Missing Amarillo and the lake, but loving Temp...\n",
       "Name: sentiment_text, Length: 1133, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        sad apl friend ... ... ... ... .\n",
       "1                                missed new moon trailer…\n",
       "2       .. omgaga . im sooo im gunna cry . 've dentist...\n",
       "3                          think mi bf cheating ! ! ! t_t\n",
       "4                                            worry much ?\n",
       "                              ...                        \n",
       "1128    missin ' someone badly . ha ha 'someone ' . 's...\n",
       "1129    missing @ kieronhughes looking forward seeing ...\n",
       "1130                        missing @ smartbrain bkk na .\n",
       "1131    missing @ twisteddspirit , move ta-hatch-a-pea...\n",
       "1132              missing amarillo lake , loving temple .\n",
       "Name: sentiment_text, Length: 1133, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df[\"sentiment_text\"] = df[\"sentiment_text\"].str.lower()\n",
    "df[\"sentiment_text\"] = df[\"sentiment_text\"].apply(word_tokenize)\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['sentiment_text']= df['sentiment_text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['sentiment_text']=df['sentiment_text'].apply(lambda x:' '.join([item for item in x]))\n",
    "df['sentiment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Extra characters form the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:, 0].values\n",
    "labels = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         sad apl friend \n",
       "1                                missed new moon trailer \n",
       "2        omgaga im sooo im gunna cry ve dentist since ...\n",
       "3                                think mi bf cheating t_t\n",
       "4                                             worry much \n",
       "                              ...                        \n",
       "1128    missin someone badly ha ha someone mystery might \n",
       "1129    missing kieronhughes looking forward seeing later\n",
       "1130                           missing smartbrain bkk na \n",
       "1131    missing twisteddspirit move ta hatch pea fresn...\n",
       "1132                 missing amarillo lake loving temple \n",
       "Name: sentiment_text, Length: 1133, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    processed_features.append(processed_feature)\n",
    "df['sentiment_text'] = np.array(processed_features)\n",
    "df['sentiment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          sad apl friend\n",
       "1                                 missed new moon trailer\n",
       "2       omgaga im sooo im gunna cry ve dentist since 1...\n",
       "3                                think mi bf cheating t_t\n",
       "4                                              worry much\n",
       "                              ...                        \n",
       "1128     missin someone badly ha ha someone mystery might\n",
       "1129    missing kieronhughes looking forward seeing later\n",
       "1130                            missing smartbrain bkk na\n",
       "1131    missing twisteddspirit move ta hatch pea fresn...\n",
       "1132                  missing amarillo lake loving temple\n",
       "Name: sentiment_text, Length: 1133, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['sentiment_text'] = df['sentiment_text'].apply(word_tokenize)\n",
    "df['sentiment_text']= df['sentiment_text'].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
    "df['sentiment_text']=df['sentiment_text'].apply(lambda x:' '.join([item for item in x]))\n",
    "df['sentiment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the dataset into numerical data using Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_feature = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=2000,min_df=3,max_df=0.6,stop_words = stopwords.words('english'))\n",
    "processed_feature = vectorizer.fit_transform(processed_feature).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_feature, labels, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148  13]\n",
      " [ 97  26]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6126760563380281"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It gives 61.2% accuracy\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "classifiersvm = SVC(kernel='linear', random_state=0)  \n",
    "classifiersvm.fit(X_train, y_train) \n",
    "y_pred = classifiersvm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138  23]\n",
      " [ 63  60]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6971830985915493"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  It gives 69.7% accuracy\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "gnb = MultinomialNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  21]\n",
      " [ 54  69]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7359154929577465"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It gives 73.5% accuracy\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg_clf = LogisticRegression(random_state = 0)\n",
    "LogReg_clf.fit(X_train, y_train)\n",
    "y_pred = LogReg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  18]\n",
      " [ 68  55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6971830985915493"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It gives 69.7% accuracy\n",
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)\n",
    "y_pred = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133  28]\n",
      " [ 51  72]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.721830985915493"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It gives 72.1% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
